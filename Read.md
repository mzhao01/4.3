# 智能语音助手部署指南

## 项目概述

智能语音助手是一个基于语音交互的问答系统，包含前端界面和后端服务两部分。前端使用Gradio构建，提供语音输入和输出功能；后端使用FastAPI构建，实现语音识别(ASR)、问答(QA)和语音合成(TTS)功能。

## 系统要求

- Python 3.8+
- pip 20.0+
- 网络连接（用于语音识别服务）

## 安装步骤

### 1. 克隆项目

```bash
git clone <GitHub仓库地址>
cd <项目目录>
```

### 2. 安装后端服务依赖

```bash
cd voice-assistant
pip install -r requirements.txt
```

### 3. 安装前端依赖

前端使用Gradio，通常已经包含在Python环境中，如果没有安装，可以执行：

```bash
pip install gradio requests
```

## 运行方法

### 1. 启动后端服务

在`voice-assistant`目录下执行：

```bash
# Windows
start.bat

# Linux/Mac
./start.sh
```

或者直接运行：

```bash
uvicorn api.main:app --host 0.0.0.0 --port 8000
```

后端服务启动后，会在 http://localhost:8000 上运行。

### 2. 启动前端界面

在项目根目录下执行：

```bash
python a_1.PY
```

前端界面启动后，会在 http://localhost:7860 上运行。

## 功能说明

### 1. 语音输入

点击前端界面右侧的"点击录音"按钮，开始录音。录音完成后，系统会自动将语音发送到后端服务进行处理。

### 2. 语音识别

后端服务接收到音频文件后，会使用SpeechRecognition库将语音转换为文本。

### 3. 问答处理

后端服务会根据识别的文本，使用内置的问答规则库生成回答。

### 4. 语音合成

后端服务会将生成的回答转换为语音，并返回给前端界面。

### 5. 对话历史

前端界面左侧会显示对话历史，包括用户的语音输入（转换为文本）和助手的回答。

## 后端API接口

### 1. 语音转文本

- 接口：`/api/asr`
- 方法：POST
- 参数：音频文件（multipart/form-data）
- 返回：识别的文本

### 2. 问答

- 接口：`/api/qa`
- 方法：POST
- 参数：问题文本
- 返回：回答文本

### 3. 文本转语音

- 接口：`/api/tts`
- 方法：POST
- 参数：文本
- 返回：音频文件

### 4. 完整处理流程

- 接口：`/api/process`
- 方法：POST
- 参数：音频文件（multipart/form-data）
- 返回：识别的文本、回答文本、音频文件URL

## 故障排除

### 1. 后端服务启动失败

- 检查端口8000是否被占用
- 检查Python依赖是否安装正确
- 检查网络连接是否正常

### 2. 前端界面无法连接到后端服务

- 检查后端服务是否启动
- 检查前端代码中的BACKEND_URL是否正确设置为"http://localhost:8000"
- 检查防火墙是否阻止了连接

### 3. 语音识别失败

- 检查网络连接是否正常（SpeechRecognition使用Google Web Speech API）
- 检查麦克风是否正常工作
- 尝试在安静的环境中录音

### 4. 语音合成失败

- 检查pyttsx3库是否安装正确
- 检查系统是否有可用的语音合成引擎

## 项目结构

```
.
├── a_1.PY               # 前端界面代码
├── voice-assistant/      # 后端服务代码
│   ├── api/             # API接口
│   ├── asr/             # 语音识别
│   ├── tts/             # 语音合成
│   ├── qa/              # 问答系统
│   ├── requirements.txt # 依赖文件
│   ├── start.bat        # Windows启动脚本
│   └── start.sh         # Linux/Mac启动脚本
└── xiaozhi-esp32-server/  # 项目文档
    └── 部署指南.md        # 部署指南
```

## 注意事项

1. 本项目使用的是免费的语音识别服务，可能有使用次数限制。

2. 语音识别的准确率受环境噪音、发音清晰度等因素影响。

3. 问答系统目前使用的是基于规则的简单实现，后续可以扩展为更复杂的模型。

4. 语音合成的质量取决于系统安装的语音引擎。

5. 本项目已移除ESP32相关依赖，可以在任何支持Python的环境中运行。
